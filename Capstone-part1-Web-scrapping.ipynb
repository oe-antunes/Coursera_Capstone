{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Data Science Professional Certificate - Capstone Final Project - Oscar Antunes\n",
    "##### \n",
    "### Analysis of Düsseldorf boroughs, Germany\n",
    "##### \n",
    "#### Webscraping for  Boroughs, Houses available, Housing prices, Habitants, Venues\n",
    "##### \n",
    "\n",
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for scrapping\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import smtplib\n",
    "import json # library to handle JSON files\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "import requests # library to handle requests\n",
    "\n",
    "\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Regular Expressions to collect the addresses\n",
    "import re\n",
    "\n",
    "# Get the same number of District cells as Boroughs\n",
    "from itertools import chain\n",
    "\n",
    "# convert an address into latitude and longitude values\n",
    "from geopy.geocoders import Nominatim \n",
    "\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# map rendering library\n",
    "import folium\n",
    "\n",
    "# Class object has been created to store the credentials for safekeeping\n",
    "#import credentials_oa_outlk\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Getting the Boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data parsed.\n",
      "Table located.\n"
     ]
    }
   ],
   "source": [
    "url_wiki = 'https://de.wikipedia.org/wiki/Liste_der_Stadtbezirke_von_D%C3%BCsseldorf'\n",
    "\n",
    "page = requests.get(url_wiki)\n",
    "# Parsing through the URL\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(\"Data parsed.\")\n",
    "\n",
    "# Identify the table to scrap\n",
    "right_table = soup.find('table', class_ = 'wikitable sortable')\n",
    "print(\"Table located.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Assigning Districts and Boroughs to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           District                                            Borough\n",
      "0  Stadtbezirk 1[1]  011 Altstadt012 Carlstadt013 Stadtmitte014 Pem...\n",
      "1  Stadtbezirk 2[2]     021 Flingern Süd022 Flingern Nord023 Düsseltal \n",
      "\n",
      "           District                                            Borough  \\\n",
      "0  Stadtbezirk ,[,]  , Altstadt, Carlstadt, Stadtmitte, Pempelfort,...   \n",
      "1  Stadtbezirk ,[,]           , Flingern Süd, Flingern Nord, Düsseltal   \n",
      "\n",
      "  district_numb  \n",
      "0             1  \n",
      "1             2  \n"
     ]
    }
   ],
   "source": [
    "# SET THE DATAFRAME COLUMNS || CREATE EMPTY DATAFRAME WITH THE SAME STRUCTURE OF THE ORIGINAL\n",
    "column_names = ['District','Borough','Fläche','Einwohner','Bewölkerungsdichte','Bezirkvorsteher','K','Karte']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "#####################################################\n",
    "# LOAD OF THE DATAFRAME || CLEAR TO THE 2 COLUMNS NEEDEED\n",
    "for tr_cell in right_table.find_all('tr'):\n",
    "    row_data = []\n",
    "    for td_cell in tr_cell.find_all('td'):\n",
    "        row_data.append(td_cell.text.rstrip())\n",
    "        \n",
    "    if len(row_data)>0:\n",
    "        df.loc[len(df)] = row_data\n",
    "        \n",
    "df = df[['District', 'Borough']]\n",
    "print(df.head(2),'\\n')\n",
    "\n",
    "#####################################################\n",
    "# REMOVE NUMERIC DIGITS FROM THE BOROUGHS\n",
    "df.set_index(['District', 'Borough'])  \n",
    "df = df.replace(regex=r'[0-9]+', value=',')\n",
    "\n",
    "# As the numeric digit has been removed from the District Column, \n",
    "# we need to add the number of each district as per the current index \n",
    "district_numb = ['1','2','3','4','5','6','7','8','9','10']\n",
    "df['district_numb'] = district_numb\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get several District cells for each Borough\n",
    "# return list from series of comma-separated strings\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(', ')))\n",
    "\n",
    "# calculate lengths of splits\n",
    "lens = df['Borough'].str.split(', ').map(len)\n",
    "\n",
    "# create new dataframe, repeating or chaining as appropriate\n",
    "res = pd.DataFrame({'District': np.repeat(df['District'], lens),\n",
    "                    'Borough': chainer(df['Borough']),\n",
    "                    'district_numb': np.repeat(df['district_numb'], lens)})\n",
    "# Strip empty cells \"\"\n",
    "res = res[res['Borough'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping of Districts and Boroughs completed!\n",
      "\n",
      "        District    Borough\n",
      "0  Stadtbezirk 1   Altstadt\n",
      "1  Stadtbezirk 1  Carlstadt\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the District to include the Number for each District\n",
    "res['Dis'] = res['District'].str[:11] \n",
    "res['District'] = res['Dis']+' '+res['district_numb']\n",
    "\n",
    "# Finalize the DataFrame with Districts and Boroughs of Düsseldorf\n",
    "df_boroughs = res[['District','Borough']]\n",
    "df_boroughs = df_boroughs.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print('Scraping of Districts and Boroughs completed!\\n')\n",
    "print(df_boroughs.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "## Getting the Coordinates for the city of Düsseldorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The geograpical coordinate of Düsseldorf are 51.2254018, 6.7763137.\n"
     ]
    }
   ],
   "source": [
    "# Getting the Coordinates for Düsseldorf\n",
    "\n",
    "address = 'Düsseldorf, NRW'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"duesseldorf_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Düsseldorf are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altstadt, Düsseldorf, Germany 51.2259125 6.7735672\n",
      "Carlstadt, Düsseldorf, Germany 51.2221416 6.7733942\n",
      "Stadtmitte, Düsseldorf, Germany 51.2219385 6.7844229\n",
      "Pempelfort, Düsseldorf, Germany 51.2396009 6.7796845\n",
      "Derendorf, Düsseldorf, Germany 51.2445487 6.7922488\n",
      "Golzheim, Düsseldorf, Germany 51.2507945 6.7599633\n",
      "Flingern Süd, Düsseldorf, Germany 51.2210094 6.8100603\n",
      "Flingern Nord, Düsseldorf, Germany 51.2313815 6.8132378\n",
      "Düsseltal, Düsseldorf, Germany 51.2378412 6.812116\n",
      "Friedrichstadt, Düsseldorf, Germany 51.2135645 6.7816997\n",
      "Unterbilk, Düsseldorf, Germany 51.210055 6.7669651\n",
      "Hafen, Düsseldorf, Germany 51.2170292 6.7335758\n",
      "Hamm, Düsseldorf, Germany 51.2035725 6.7388087\n",
      "Volmerswerth, Düsseldorf, Germany 51.1885784 6.7490097\n",
      "Bilk, Düsseldorf, Germany 51.2027583 6.7851015\n"
     ]
    },
    {
     "ename": "GeocoderUnavailable",
     "evalue": "Service not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1319\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    937\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 938\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 101] Network is unreachable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1362\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 101] Network is unreachable>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGeocoderUnavailable\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1333ff96ad6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mborough\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboroughs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mborough\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geopy/geocoders/osm.py\u001b[0m in \u001b[0;36mgeocode\u001b[0;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         return self._parse_json(\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         )\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderTimedOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Service timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m\"unreachable\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderUnavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Service not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderTimedOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Service timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGeocoderUnavailable\u001b[0m: Service not available"
     ]
    }
   ],
   "source": [
    "city = 'Düsseldorf, Germany'\n",
    "boroughs  = df_boroughs['Borough']\n",
    "coord = {'latitude':[],'longitude':[]}\n",
    "for borough in boroughs:\n",
    "    address = borough + ', ' + city\n",
    "    location = geolocator.geocode(address)\n",
    "    lat = location.latitude\n",
    "    coord['latitude'].append(lat)\n",
    "    lng = location.longitude\n",
    "    coord['longitude'] .append(lng)\n",
    "    \n",
    "    print(address, lat, lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boroughs['latitude'] = coord['latitude']\n",
    "df_boroughs['longitude'] = coord['longitude']\n",
    "df_boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at Düsseldorf's Boroughs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Düsseldorf using latitude and longitude values\n",
    "map_dusseldorf = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, district, borough in zip(df_boroughs['latitude'], df_boroughs['longitude'], df_boroughs['District'], df_boroughs['Borough']):\n",
    "    label = '{}, {}'.format(borough, district)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_dusseldorf)  \n",
    "    \n",
    "map_dusseldorf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "## Getting the number of habitants per borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_hab = 'http://www.citypopulation.de/en/germany/dusseldorf/admin/'\n",
    "page = requests.get(url_hab)\n",
    "\n",
    "    \n",
    "# Parsing through the URL\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_2018 = {'Borough':[], 'Population':[]}\n",
    "\n",
    "for n in soup.find_all(itemprop=\"name\"):\n",
    "    n = n.decode()\n",
    "    stuff = re.findall((r\">(.*)\\<\"), n)\n",
    "    if len(stuff) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        temp = []\n",
    "        temp.append(stuff)\n",
    "        for sublist in temp:\n",
    "            for item in sublist:\n",
    "                pop_2018['Borough'].append(item)\n",
    "    \n",
    "#Remove Continent and Country names + Removing old borough that was surpressed            \n",
    "pop_2018['Borough'] = pop_2018['Borough'][3:45]+pop_2018['Borough'][46:] \n",
    "\n",
    "\n",
    "for p in soup.find_all('td', class_=['admin2', 'rpop prio1']):\n",
    "        p = p.decode()\n",
    "        stuff = re.findall((r'[0-9][0-9,.]+'),p)\n",
    "        if len(stuff) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            temp = []\n",
    "            temp.append(stuff)\n",
    "            for sublist in temp:\n",
    "                for item in sublist:\n",
    "                    pop_2018['Population'].append(item)\n",
    "\n",
    "\n",
    "pd_name = pd.Series(pop_2018['Borough'], dtype=object)\n",
    "pd_pop = pd.Series(pop_2018['Population'], dtype=object)\n",
    "population = pd.concat([pd_name, pd_pop], axis=1, sort=False)\n",
    "population.columns = ['Borough', 'Population']\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Adding the Population to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dusseldorf = pd.merge(df_boroughs, population[['Borough','Population']],on='Borough')\n",
    "df_dusseldorf['Population'] = df_dusseldorf['Population'].str.replace(\",\",\"\").astype(int)\n",
    "df_dusseldorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo JSON of StadtTeile --> https://opendata.duesseldorf.de/sites/default/files/Stadtteile_WGS84_4326.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download countries geojson file\n",
    "!wget --quiet https://opendata.duesseldorf.de/sites/default/files/Stadtteile_WGS84_4326.geojson -O dusseldorf.json\n",
    "    \n",
    "print('GeoJSON file downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dusseldorf_geo = r'dusseldorf.json' # geojson file\n",
    "\n",
    "# create a numpy array of length 6 and has linear spacing from the minium total immigration to the maximum total immigration\n",
    "threshold_scale = np.linspace(df_dusseldorf['Population'].min(),\n",
    "                              df_dusseldorf['Population'].max(),\n",
    "                              6, dtype=int)\n",
    "threshold_scale = threshold_scale.tolist() # change the numpy array to a list\n",
    "threshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n",
    "\n",
    "\n",
    "# create a plain world map\n",
    "dusseldorf_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='Mapbox Bright')\n",
    "# generate choropleth map using the total immigration of each country to Canada from 1980 to 2013\n",
    "dusseldorf_map.choropleth(\n",
    "    geo_data=dusseldorf_geo,\n",
    "    data=df_dusseldorf,\n",
    "    columns=['Borough', 'Population'],\n",
    "    key_on='feature.properties.Name',\n",
    "    threshold_scale=threshold_scale,\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.2,\n",
    "    legend_name='Population of Dusseldorf - 2018',\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(0,len(df_dusseldorf['Borough'])):\n",
    "    folium.Marker([df_dusseldorf.iloc[i]['longitude'], \n",
    "                   df_dusseldorf.iloc[i]['latitude']], \n",
    "                  popup=df_dusseldorf.iloc[i]['Borough']).add_to(dusseldorf_map)\n",
    "\n",
    "\n",
    "# display map\n",
    "dusseldorf_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Scrapping housing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnumber = 1 \n",
    "housing = {'Address':[], 'Price':[], 'Rooms':[], 'Borough':[]}\n",
    "\n",
    "while pnumber < 32:\n",
    "    url_house = 'https://www.immobilienscout24.de/Suche/radius/wohnung-mieten?centerofsearchaddress=D%C3%BCsseldorf;;;1276010012;Nordrhein-Westfalen;&numberofrooms=1.0-&price=-3500.0&geocoordinates=51.23824;6.81513;3.0&sorting=4&pagenumber={}'.format(pnumber)\n",
    "    headers = {\"User-agent\": 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
    "\n",
    "    page = requests.get(url_house, headers=headers)\n",
    "    \n",
    "    # Parsing through the URL\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Check if pages are being scraped\n",
    "    print('Page {} scraped'.format(pnumber))\n",
    "    \n",
    "    #Getting Address\n",
    "    address  = soup.find_all('button')\n",
    "    \n",
    "    for a in address:\n",
    "        a = a.decode()\n",
    "        stuff = re.findall((\"[^<>]+\\w+[A-Za-z].\\\\s+Düsseldorf\"), a)\n",
    "        if len(stuff) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            temp = []\n",
    "            temp.append(stuff)\n",
    "            for sublist in temp:\n",
    "                for item in sublist:\n",
    "                    housing['Address'].append(item)\n",
    "    \n",
    "    #Getting price\n",
    "    price  = soup.find_all('dd')\n",
    "    \n",
    "    for p in price:\n",
    "        p = p.decode()\n",
    "        stuff = re.findall((\"[^<>]+\\\\s+€\"),p)\n",
    "        if len(stuff) == 0:\n",
    "            continue\n",
    "        else:        \n",
    "            temp = []\n",
    "            temp.append(stuff)\n",
    "            for sublist in temp:\n",
    "                for item in sublist:\n",
    "                    housing['Price'].append(item)\n",
    "    \n",
    "    #Getting number of rooms\n",
    "    rooms = soup.find_all(class_=['onlySmall'])\n",
    "    \n",
    "    for r in rooms:\n",
    "        r = r.decode()\n",
    "        stuff = re.findall((\"[>]+[0-9]+[<]\"), r)\n",
    "        if len(stuff) == 0:\n",
    "            continue\n",
    "        else:   \n",
    "            temp = []\n",
    "            temp.append(stuff)\n",
    "            for sublist in temp:\n",
    "                for item in sublist:\n",
    "                    housing['Rooms'].append(item)\n",
    "    \n",
    "    # Scrape the next page and keep running the While Loop\n",
    "    pnumber = pnumber + 1\n",
    "\n",
    "print(\"\\nScraping completed.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the Borough from the Address Field - Not all houses have the full address\n",
    "for address in housing['Address']:\n",
    "    temp = address.split(\", \")\n",
    "    housing['Borough'].append(temp[-2])\n",
    "\n",
    "pd_borough = pd.Series(housing['Borough'], dtype = object)\n",
    "pd_price = pd.Series(housing['Price'], dtype = object)\n",
    "pd_rooms = pd.Series(housing['Rooms'], dtype = object)\n",
    "\n",
    "# Finishing cleaning the number of rooms\n",
    "pd_rooms = pd_rooms.str[1]\n",
    "\n",
    "# Concatenating the Series into a Pandas DataFrame\n",
    "result = pd.concat([pd_borough, pd_price, pd_rooms], axis=1, sort=False)\n",
    "result.columns = ['Borough', 'Price', 'Num_Rooms']\n",
    "\n",
    "##### Cleaning the new DataFrame - Remove NaN\n",
    "# Turning the numerical values [Price and Number of Rooms] into numbers\n",
    "result['Price'] = result['Price'].map(lambda x: x.rstrip(' €'))\n",
    "result['Price'] = result['Price'].str.replace(\".\",\"\")\n",
    "result['Price'] = result['Price'].str.replace(\",\",\".\").astype(float)\n",
    "result = result.dropna()\n",
    "result['Num_Rooms'] = result['Num_Rooms'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Num_Rooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_one = result.groupby(['Borough'],as_index=False).mean()\n",
    "df_group_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_two = result.groupby(['Borough'],as_index=False).median()\n",
    "df_group_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_three = pd.merge(df_group_one, df_group_two[['Borough','Price','Num_Rooms']],on='Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_group_one = df_dusseldorf.groupby(['drive-wheels'],as_index=False).mean()\n",
    "#df_group_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.manausa.com/blog/mean-median-mode-real-estate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://math.stackexchange.com/questions/2304710/mean-vs-median-when-to-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
